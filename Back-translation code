import torch
import pandas as pd
from transformers import MarianMTModel, MarianTokenizer
from tqdm import tqdm

# Check for GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Function to load MarianMT model and tokenizer
def load_model(src_lang, tgt_lang):
    model_name = f"Helsinki-NLP/opus-mt-{src_lang}-{tgt_lang}"
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    model = MarianMTModel.from_pretrained(model_name).to(device)  # Move model to GPU
    return model, tokenizer

# Function to perform translation on GPU (supports batch processing)
def batch_translate(texts, model, tokenizer, batch_size=8):
    translated_texts = []
    
    for i in tqdm(range(0, len(texts), batch_size), desc="Translating"):
        batch = texts[i : i + batch_size]
        inputs = tokenizer(batch, return_tensors="pt", padding=True, truncation=True, max_length=512).to(device)
        translated = model.generate(**inputs)
        translated_texts.extend(tokenizer.batch_decode(translated, skip_special_tokens=True))
    
    return translated_texts

# Load the dataset (Ensure the dataset is uploaded to Kaggle)
df = pd.read_excel("/kaggle/input/isear-dataset/ISEAR.xlsx")  # Update with actual dataset name

# Ensure dataset has correct columns
if "content" not in df.columns or "labels" not in df.columns:
    raise ValueError("Dataset must contain 'content' and 'labels' columns")

# Drop empty texts to prevent translation errors
df = df.dropna(subset=["content"])

# Load translation models
model_en_fr, tokenizer_en_fr = load_model("en", "fr")
model_fr_en, tokenizer_fr_en = load_model("fr", "en")

# Apply back-translation in batches
df["back_translated_content"] = batch_translate(
    batch_translate(df["content"].tolist(), model_en_fr, tokenizer_en_fr), 
    model_fr_en, tokenizer_fr_en
)

# Save the dataset to Kaggle output directory
output_path = "/kaggle/working/ISEAR_back_translated.csv"
df.to_csv(output_path, index=False)

print(f"Back-translation completed. Dataset saved to: {output_path}")
